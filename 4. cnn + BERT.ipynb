{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "oOrQnfUOmxQS",
   "metadata": {
    "id": "oOrQnfUOmxQS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53bbd4b2",
   "metadata": {
    "id": "53bbd4b2"
   },
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f46d885-2f76-42aa-aad5-8643b1c54a6a",
   "metadata": {
    "id": "4f46d885-2f76-42aa-aad5-8643b1c54a6a"
   },
   "outputs": [],
   "source": [
    "# Load training and validation datasets\n",
    "train_data = pd.read_csv(\"./train_2024.csv\")\n",
    "valid_data = pd.read_csv(\"./dev_2024.csv\")\n",
    "\n",
    "X_train = tf.convert_to_tensor(train_data[\"text\"])\n",
    "y_train = tf.convert_to_tensor(train_data[\"label\"])\n",
    "X_val = tf.convert_to_tensor(valid_data[\"text\"])\n",
    "y_val = tf.convert_to_tensor(valid_data[\"label\"])\n",
    "\n",
    "# Unsqueeze the X tensors (x,) -> (x,1)\n",
    "X_train = tf.reshape(X_train, (len(X_train), 1))\n",
    "X_val = tf.reshape(X_val, (len(X_val), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a76cf3e5-fea8-401c-b3c6-1de32de80828",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a76cf3e5-fea8-401c-b3c6-1de32de80828",
    "outputId": "93a8dbfa-08d7-413e-8d8c-76081c990812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of training input:\n",
      "b'Except that Desmond played first base last night. Tapia was in LF  and Reynolds had a night off.' maps to label 0\n",
      "Example of validation input:\n",
      "b'He was older  and was carrying a small bucket.' maps to label 0\n",
      "Training dataset size is 98629 and validation dataset size is 10980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Example of training input:\\n{X_train[0][0].numpy()} maps to label {y_train[0].numpy()}\")\n",
    "print(f\"Example of validation input:\\n{X_val[0][0].numpy()} maps to label {y_val[0].numpy()}\")\n",
    "print(f\"Training dataset size is {len(y_train)} and validation dataset size is {len(y_val)}\")\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "sjm2TUcpfYwm",
   "metadata": {
    "id": "sjm2TUcpfYwm"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "MAX_LENGTH = 50\n",
    "LR = 2e-5\n",
    "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "  return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label\n",
    "\n",
    "def encode(X, y):\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "\n",
    "      for i in tqdm(range(len(X))):\n",
    "            bert_input = tokenizer.encode_plus(\n",
    "                            str(X[i][0].numpy().decode('utf-8')),\n",
    "                            add_special_tokens=True,\n",
    "                            max_length = MAX_LENGTH, # max length of the text that can go to BERT\n",
    "                            pad_to_max_length = True, # add [PAD] tokens\n",
    "                            return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "                            truncation=True\n",
    "              )\n",
    "    input_ids_list.append(bert_input[\"input_ids\"])\n",
    "    token_type_ids_list.append(bert_input[\"token_type_ids\"])\n",
    "    attention_mask_list.append(bert_input[\"attention_mask\"])\n",
    "    label_list.append(y[i])\n",
    "\n",
    "      return np.array(input_ids_list), np.array(attention_mask_list), np.array(label_list)\n",
    "  #return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "mpTIUTxhj0O7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpTIUTxhj0O7",
    "outputId": "eb9eb1c3-cd9f-4a26-96eb-80611ad14d58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98629 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 98629/98629 [03:45<00:00, 436.65it/s]\n",
      "100%|██████████| 10980/10980 [00:24<00:00, 457.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ids, train_attention_masks, train_labels = encode(X_train, y_train)\n",
    "val_ids, val_attention_masks, val_labels = encode(X_val, y_val)\n",
    "\n",
    "#train_dataset = encode(X_train, y_train)\n",
    "#val_dataset = encode(X_val, y_val)\n",
    "#print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c5X4l_kOPZ8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c5X4l_kOPZ8",
    "outputId": "24293dca-0c24-4542-c2f2-e6cae099eb23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  2205  2919 21591  2187  3358  8351  2066  2017  1999  1996  3915\n",
      "  2024 26476  2098  2296  2154  2011  1996  4507  1997  3974   999   999\n",
      "   999   999  2009  2097  2022  2488  2449  2084  1996  3915  2038  2464\n",
      "  1999  5109 10916   102     0     0     0     0     0     0     0     0\n",
      "     0     0] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0] 1\n"
     ]
    }
   ],
   "source": [
    "print(train_ids[0], train_attention_masks[0], train_labels[0])\n",
    "#train_dataset = train_dataset.batch(32)\n",
    "#val_dataset = val_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "flDQOJZ1k6gC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flDQOJZ1k6gC",
    "outputId": "90c0509a-5f56-457f-9c8c-88e5c81aa301"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_1481 (Dropout)      multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109483778 (417.65 MB)\n",
      "Trainable params: 109483778 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "print(model.summary())\n",
    "opt = \"adam\" # Adam(learning_rate=2e-5,epsilon=1e-08) # Fucks sake, wont interpret optimizer adam.Adam -object, lr=0.001 and high epsilon fuck up finetune\n",
    "loss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c1eacc19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1eacc19",
    "outputId": "adb23e12-612d-4d78-9432-b309517baf50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3083/3083 [==============================] - 1120s 341ms/step - loss: 0.6806 - accuracy: 0.6052 - val_loss: 0.7116 - val_accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    checkpoint_filepath = './checkpoint.keras'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    model.fit([train_ids, train_attention_masks], train_labels,\n",
    "              epochs=1,\n",
    "              batch_size=32,\n",
    "              validation_data=([val_ids, val_attention_masks], val_labels),\n",
    "              callbacks=[model_checkpoint_callback],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09212fbe-e5a1-48a1-985e-03c8ef9a0108",
   "metadata": {
    "id": "09212fbe-e5a1-48a1-985e-03c8ef9a0108"
   },
   "outputs": [],
   "source": [
    "def save_model(path: str, model):\n",
    "    model.save_weights(path)\n",
    "\n",
    "def load_model(path: str, model):\n",
    "    model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "07a92b74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07a92b74",
    "outputId": "84d05178-a9f5-46e5-dec2-d3ee4bb13fa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    # path must en in .weights.h5 as in checkpoint format\n",
    "    model.load_weights(\"checkpoint.keras\")\n",
    "    save_model(\"./model_best2.weights.h5\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9da48d-0980-463d-9674-1bcabce964ad",
   "metadata": {
    "id": "2f9da48d-0980-463d-9674-1bcabce964ad"
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    load_model(\"./model_best2.weights.h5\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05bfa70a-e6ef-472c-810f-1dc8a2917abf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05bfa70a-e6ef-472c-810f-1dc8a2917abf",
    "outputId": "85179452-a08e-4d26-fe1e-4c7cd3eccb32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run the tests with trained model\n",
    "\n",
    "test_data = pd.read_csv(\"./test_2024.csv\", quoting=3)\n",
    "X_test = tf.convert_to_tensor(test_data[\"text\"])\n",
    "X_test = tf.reshape(X_test, (len(X_test), 1))\n",
    "\n",
    "input_ids_list = []\n",
    "token_type_ids_list = []\n",
    "attention_mask_list = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    bert_input = tokenizer.encode_plus(\n",
    "                        str(X_test[i][0].numpy().decode('utf-8')),\n",
    "                        max_length = MAX_LENGTH,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        truncation=True\n",
    "              )\n",
    "    input_ids_list.append(bert_input[\"input_ids\"])\n",
    "    token_type_ids_list.append(bert_input[\"token_type_ids\"])\n",
    "    attention_mask_list.append(bert_input[\"attention_mask\"])\n",
    "\n",
    "test_ids = np.array(input_ids_list)\n",
    "test_attention_masks = np.array(attention_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "B5bT_wZlu87R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5bT_wZlu87R",
    "outputId": "8099419b-598b-4306-ab6c-b88f41ff29dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 44s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict([test_ids, test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "63e22181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63e22181",
    "outputId": "04628456-0205-4c09-fbf2-0b6ec362cd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Predictions are of shape (12001,) and head of predictions is:\n",
      "<bound method NDFrame.head of        0\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "...   ..\n",
      "11996  1\n",
      "11997  1\n",
      "11998  1\n",
      "11999  1\n",
      "12000  1\n",
      "\n",
      "[12001 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "y_preds_clean = np.argmax(y_preds.logits, axis=-1)\n",
    "print(y_preds_clean)\n",
    "print(f\"Predictions are of shape {y_preds_clean.shape} and head of predictions is:\")\n",
    "#rounded = np.where(y_preds.numpy() > 0.5, 1, 0)\n",
    "ans_df = pd.DataFrame(y_preds_clean)\n",
    "print(ans_df.head)\n",
    "\n",
    "final_df = pd.concat([test_data[\"text\"], ans_df], axis=1)\n",
    "\n",
    "final_df.to_csv(\"./bert_preds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
